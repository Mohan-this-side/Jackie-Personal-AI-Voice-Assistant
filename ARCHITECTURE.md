# ğŸ—ï¸ Jackie AI Assistant - Detailed Architecture

This document provides a comprehensive overview of Jackie's system architecture, technology stack, and data flow patterns.

## ğŸŒ High-Level System Architecture

```mermaid
graph TB
    subgraph "Client Layer"
        Browser[Web Browser]
        UI[React-like UI]
        WS_Client[WebSocket Client]
        Audio_API[Web Audio API]
    end

    subgraph "Network Layer"
        HTTPS[HTTPS/WSS]
        CDN[Modal CDN]
    end

    subgraph "Modal.com Infrastructure"
        subgraph "Application Layer"
            FastAPI[FastAPI Server]
            WebSocket[WebSocket Handler]
            ASGI[ASGI Application]
        end
        
        subgraph "Business Logic Layer"
            VoiceAssistant[Voice Assistant Core]
            WebSearcher[Web Search Engine]
            ContextManager[Context Manager]
        end
        
        subgraph "AI Processing Layer"
            STT_Pipeline[Speech-to-Text Pipeline]
            LLM_Engine[Language Model Engine]
            TTS_Pipeline[Text-to-Speech Pipeline]
        end
    end

    subgraph "External AI Services"
        Groq[Groq API<br/>LLM + STT]
        OpenAI[OpenAI API<br/>STT/TTS Fallback]
        EdgeTTS[Microsoft Edge TTS]
        LocalWhisper[Local Whisper Model]
    end

    subgraph "Data Services"
        DuckDuckGo[DuckDuckGo Search API]
        WebScraper[BeautifulSoup Scraper]
    end

    subgraph "Configuration"
        Secrets[Modal Secrets]
        Context[Personal Context]
        Config[Environment Config]
    end

    %% Client connections
    Browser --> UI
    UI --> Audio_API
    UI --> WS_Client
    
    %% Network flow
    WS_Client -.-> HTTPS
    HTTPS -.-> CDN
    CDN -.-> FastAPI
    
    %% Application flow
    FastAPI --> WebSocket
    WebSocket --> VoiceAssistant
    VoiceAssistant --> STT_Pipeline
    VoiceAssistant --> LLM_Engine
    VoiceAssistant --> TTS_Pipeline
    VoiceAssistant --> WebSearcher
    
    %% AI service connections
    STT_Pipeline --> Groq
    STT_Pipeline --> LocalWhisper
    STT_Pipeline --> OpenAI
    LLM_Engine --> Groq
    TTS_Pipeline --> EdgeTTS
    TTS_Pipeline --> OpenAI
    
    %% Data service connections
    WebSearcher --> DuckDuckGo
    WebSearcher --> WebScraper
    
    %% Configuration
    VoiceAssistant --> Secrets
    VoiceAssistant --> Context
    FastAPI --> Config

    %% Styling
    classDef client fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef network fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef modal fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px
    classDef ai fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef data fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef config fill:#f1f8e9,stroke:#33691e,stroke-width:2px

    class Browser,UI,WS_Client,Audio_API client
    class HTTPS,CDN network
    class FastAPI,WebSocket,ASGI,VoiceAssistant,WebSearcher,ContextManager,STT_Pipeline,LLM_Engine,TTS_Pipeline modal
    class Groq,OpenAI,EdgeTTS,LocalWhisper ai
    class DuckDuckGo,WebScraper data
    class Secrets,Context,Config config
```

## ğŸ”„ Data Flow Architecture

### **1. Voice Interaction Flow**

```mermaid
sequenceDiagram
    participant User
    participant Browser
    participant WebSocket
    participant VoiceAssistant
    participant STT as STT Pipeline
    participant LLM as LLM Engine
    participant TTS as TTS Pipeline
    participant Groq
    participant EdgeTTS

    User->>Browser: ğŸ¤ Speaks into microphone
    Browser->>Browser: ğŸ“¹ Records audio (Web Audio API)
    Browser->>WebSocket: ğŸ“¤ Sends audio data (base64)
    
    WebSocket->>VoiceAssistant: ğŸ”„ Process audio request
    VoiceAssistant->>STT: ğŸ¤ Convert speech to text
    
    alt Primary STT (Groq)
        STT->>Groq: ğŸ“¡ Send audio data
        Groq-->>STT: ğŸ“ Return transcription
    else Fallback STT (Local Whisper)
        STT->>STT: ğŸ  Process locally
    end
    
    STT-->>VoiceAssistant: âœ… Return transcribed text
    VoiceAssistant->>WebSocket: ğŸ“¤ Send transcription
    WebSocket->>Browser: ğŸ“¥ Display transcription
    
    VoiceAssistant->>LLM: ğŸ§  Generate response
    LLM->>Groq: ğŸ“¡ Send query + context
    Groq-->>LLM: ğŸ’¬ Return AI response
    
    VoiceAssistant->>TTS: ğŸ”Š Convert text to speech
    TTS->>EdgeTTS: ğŸ“¡ Generate audio
    EdgeTTS-->>TTS: ğŸµ Return audio data
    
    TTS-->>VoiceAssistant: âœ… Return audio
    VoiceAssistant->>WebSocket: ğŸ“¤ Send response + audio
    WebSocket->>Browser: ğŸ“¥ Receive response
    Browser->>User: ğŸ”Š Play audio response
```

### **2. Web Search Integration Flow**

```mermaid
sequenceDiagram
    participant User
    participant LLM as LLM Engine
    participant WebSearcher
    participant DuckDuckGo
    participant Scraper as Web Scraper
    participant Context as Context Manager

    User->>LLM: â“ "What are the latest AI trends?"
    LLM->>LLM: ğŸ” Detect current info needed
    LLM->>WebSearcher: ğŸŒ Request web search
    
    WebSearcher->>DuckDuckGo: ğŸ” Search query
    DuckDuckGo-->>WebSearcher: ğŸ“‹ Return search results
    
    loop For each result
        WebSearcher->>Scraper: ğŸ“„ Extract page content
        Scraper-->>WebSearcher: ğŸ“ Return cleaned text
    end
    
    WebSearcher-->>LLM: ğŸ“Š Compiled search results
    LLM->>Context: ğŸ”„ Combine with personal context
    Context-->>LLM: ğŸ“‹ Enhanced context
    LLM-->>User: ğŸ’¬ AI response with current info
```

## ğŸ› ï¸ Technology Stack Breakdown

### **Frontend Technologies**
```mermaid
graph LR
    subgraph "Browser APIs"
        WebAudio[Web Audio API<br/>ğŸ¤ Audio Recording]
        WebSocket_API[WebSocket API<br/>ğŸ“¡ Real-time Communication]
        MediaRecorder[MediaRecorder API<br/>ğŸ¬ Audio Capture]
    end
    
    subgraph "UI Framework"
        HTML5[HTML5<br/>ğŸ“„ Structure]
        CSS3[CSS3<br/>ğŸ¨ Styling & Animation]
        JavaScript[Vanilla JavaScript<br/>âš¡ Interactivity]
    end
    
    subgraph "Audio Processing"
        Base64[Base64 Encoding<br/>ğŸ” Audio Transport]
        AudioContext[Audio Context<br/>ğŸµ Audio Management]
    end

    WebAudio --> MediaRecorder
    MediaRecorder --> Base64
    WebSocket_API --> JavaScript
    HTML5 --> CSS3
    CSS3 --> JavaScript
```

### **Backend Technologies**
```mermaid
graph TB
    subgraph "Web Framework"
        FastAPI[FastAPI 0.104.1<br/>ğŸš€ High-performance API]
        Uvicorn[Uvicorn<br/>âš¡ ASGI Server]
        WebSockets[WebSockets 12.0<br/>ğŸ”„ Real-time Communication]
    end
    
    subgraph "AI/ML Libraries"
        Groq_Client[Groq 0.4.1<br/>ğŸ§  Ultra-fast LLM]
        OpenAI_Client[OpenAI 1.3.8<br/>ğŸ¤– Fallback AI Services]
        Whisper[Whisper 1.1.10<br/>ğŸ¤ Local Speech Recognition]
        Transformers[Transformers 4.35.2<br/>ğŸ”§ Model Loading]
    end
    
    subgraph "Audio Processing"
        LibROSA[LibROSA 0.10.1<br/>ğŸµ Audio Analysis]
        SoundFile[SoundFile 0.12.1<br/>ğŸ“ Audio I/O]
        TorchAudio[TorchAudio 2.1.0<br/>ğŸ”Š Audio Tensor Ops]
        EdgeTTS[Edge-TTS 6.1.9<br/>ğŸ—£ï¸ Microsoft TTS]
    end
    
    subgraph "Data Processing"
        NumPy[NumPy 1.24.3<br/>ğŸ”¢ Numerical Computing]
        SciPy[SciPy 1.11.4<br/>ğŸ“Š Scientific Computing]
        PyTorch[PyTorch 2.1.0<br/>ğŸ§® Deep Learning]
    end
    
    subgraph "Web & Search"
        HTTPX[HTTPX 0.24.1<br/>ğŸŒ Async HTTP Client]
        BeautifulSoup[BeautifulSoup4<br/>ğŸ² HTML Parsing]
        DuckDuckGo_Search[DuckDuckGo-Search<br/>ğŸ” Privacy Search]
    end

    FastAPI --> WebSockets
    FastAPI --> Groq_Client
    Groq_Client --> OpenAI_Client
    Whisper --> LibROSA
    LibROSA --> SoundFile
    EdgeTTS --> TorchAudio
```

### **Infrastructure & Deployment**
```mermaid
graph TB
    subgraph "Modal.com Platform"
        Container[Debian Slim Container<br/>ğŸ§ Lightweight Linux]
        AutoScale[Auto-scaling<br/>ğŸ“ˆ Dynamic Resources]
        Secrets[Encrypted Secrets<br/>ğŸ” API Key Management]
        Monitoring[Built-in Monitoring<br/>ğŸ“Š Performance Tracking]
    end
    
    subgraph "Network & Security"
        HTTPS_TLS[HTTPS/TLS 1.3<br/>ğŸ”’ Encrypted Communication]
        WSS[WebSocket Secure<br/>ğŸ›¡ï¸ Secure Real-time]
        CDN[Global CDN<br/>ğŸŒ Fast Content Delivery]
    end
    
    subgraph "Development Tools"
        Python38[Python 3.8+<br/>ğŸ Runtime Environment]
        PIP[Pip Package Manager<br/>ğŸ“¦ Dependency Management]
        Git[Git Version Control<br/>ğŸ“ Source Control]
    end

    Container --> AutoScale
    AutoScale --> Secrets
    Secrets --> Monitoring
    HTTPS_TLS --> WSS
    WSS --> CDN
```

## ğŸ¯ Component Architecture

### **1. Voice Assistant Core**

```mermaid
classDiagram
    class VoiceAssistant {
        +groq_client: Groq
        +openai_client: OpenAI
        +local_whisper: WhisperModel
        +web_searcher: WebSearcher
        +speech_to_text(audio_data)
        +generate_response(user_message)
        +text_to_speech(text)
        -_groq_speech_to_text()
        -_local_speech_to_text()
        -_openai_speech_to_text()
        -_edge_text_to_speech()
        -_needs_web_search()
    }
    
    class WebSearcher {
        +search_web(query, max_results)
        +get_page_content(url, max_chars)
        +search_and_summarize(query)
    }
    
    class STTProcessor {
        +groq_whisper()
        +local_whisper()
        +openai_whisper()
        +fallback_chain()
    }
    
    class TTSProcessor {
        +edge_tts()
        +openai_tts()
        +simple_beep()
        +fallback_chain()
    }
    
    VoiceAssistant --> WebSearcher
    VoiceAssistant --> STTProcessor
    VoiceAssistant --> TTSProcessor
```

### **2. API Integration Architecture**

```mermaid
graph TB
    subgraph "API Priority Chain"
        direction TB
        Primary[Primary APIs<br/>âš¡ Groq + Edge TTS]
        Secondary[Secondary APIs<br/>ğŸ”„ OpenAI Fallbacks]
        Local[Local Processing<br/>ğŸ  Whisper + Beep]
    end
    
    subgraph "Groq Integration"
        GroqLLM[Groq LLM<br/>llama-3.3-70b-versatile<br/>ğŸ’° ~$0.02/hour]
        GroqSTT[Groq Whisper<br/>whisper-large-v3<br/>ğŸ¤ Ultra-fast STT]
    end
    
    subgraph "Microsoft Integration"
        EdgeTTS_Service[Edge TTS<br/>en-US-AriaNeural<br/>ğŸ—£ï¸ FREE High-quality]
    end
    
    subgraph "OpenAI Integration"
        OpenAI_LLM[OpenAI GPT<br/>Fallback Only<br/>ğŸ’° Pay-per-use]
        OpenAI_STT[OpenAI Whisper<br/>whisper-1<br/>ğŸ¤ Fallback STT]
        OpenAI_TTS[OpenAI TTS<br/>tts-1 alloy voice<br/>ğŸ”Š Fallback TTS]
    end
    
    Primary --> GroqLLM
    Primary --> GroqSTT
    Primary --> EdgeTTS_Service
    
    Secondary --> OpenAI_LLM
    Secondary --> OpenAI_STT
    Secondary --> OpenAI_TTS
    
    Local --> LocalWhisper[Local Whisper<br/>base model<br/>ğŸ  FREE Processing]
    Local --> BeepFallback[Simple Beep<br/>numpy generated<br/>ğŸ”Š Last resort]
```

## âš¡ Performance Architecture

### **Response Time Breakdown**

```mermaid
gantt
    title Jackie Response Timeline (Target: <7 seconds)
    dateFormat X
    axisFormat %s

    section Audio Processing
    Audio Capture (Browser)    :0, 1s
    STT Processing (Groq)      :1s, 2s
    
    section AI Processing  
    LLM Generation (Groq)      :2s, 4s
    Web Search (if needed)     :3s, 5s
    
    section Audio Generation
    TTS Processing (Edge)      :4s, 6s
    Audio Playback (Browser)   :6s, 7s
```

### **Scalability Architecture**

```mermaid
graph TB
    subgraph "Modal Auto-scaling"
        Cold[Cold Start<br/>~30s initial load]
        Warm[Warm Instances<br/>keep_warm=1]
        Scale[Auto Scale<br/>0 to âˆ instances]
    end
    
    subgraph "Performance Optimization"
        Cache[Model Caching<br/>Faster subsequent calls]
        Parallel[Parallel Processing<br/>STT + Web Search]
        Streaming[Streaming Responses<br/>Real-time feedback]
    end
    
    subgraph "Resource Management"
        CPU[CPU: 2 cores<br/>Sufficient for AI calls]
        Memory[Memory: 1GB<br/>Model loading + processing]
        Timeout[Timeout: 5 min<br/>Long enough for processing]
    end
    
    Cold --> Warm
    Warm --> Scale
    Scale --> Cache
    Cache --> Parallel
    Parallel --> Streaming
```

## ğŸ”’ Security Architecture

### **Data Flow Security**

```mermaid
graph TB
    subgraph "Client Security"
        HTTPS_Client[HTTPS Only<br/>ğŸ”’ Encrypted transport]
        WSS_Client[WSS Protocol<br/>ğŸ›¡ï¸ Secure WebSocket]
        NoStorage[No Local Storage<br/>ğŸš« No data persistence]
    end
    
    subgraph "Application Security"
        EnvVars[Environment Variables<br/>ğŸ” No hardcoded secrets]
        Secrets_Modal[Modal Secrets<br/>ğŸ—ï¸ Encrypted key storage]
        Isolation[Container Isolation<br/>ğŸ  Separate instances]
    end
    
    subgraph "API Security"
        APIKey[API Key Rotation<br/>ğŸ”„ Regular key updates]
        RateLimit[Rate Limiting<br/>â±ï¸ Abuse prevention]
        Monitoring[Usage Monitoring<br/>ğŸ“Š Anomaly detection]
    end
    
    subgraph "Privacy Protection"
        NoLogs[No Conversation Logs<br/>ğŸš« No data retention]
        Anonymous[Anonymous Usage<br/>ğŸ‘¤ No user tracking]
        Personal[Private Context<br/>ğŸ”’ Gitignored personal data]
    end

    HTTPS_Client --> WSS_Client
    WSS_Client --> NoStorage
    EnvVars --> Secrets_Modal
    Secrets_Modal --> Isolation
    APIKey --> RateLimit
    RateLimit --> Monitoring
    NoLogs --> Anonymous
    Anonymous --> Personal
```

## ğŸ“Š Monitoring & Analytics Architecture

### **Performance Monitoring**

```mermaid
graph LR
    subgraph "Real-time Metrics"
        ResponseTime[Response Time<br/>ğŸ“ˆ <7s target]
        ErrorRate[Error Rate<br/>ğŸ“‰ <1% target]
        Throughput[Throughput<br/>ğŸ”„ Requests/minute]
    end
    
    subgraph "Modal Dashboard"
        Logs[Application Logs<br/>ğŸ“ Debug information]
        Usage[Resource Usage<br/>ğŸ’» CPU/Memory/Network]
        Costs[Cost Tracking<br/>ğŸ’° API usage costs]
    end
    
    subgraph "Browser Analytics"
        ClientMetrics[Client Performance<br/>âš¡ Browser timing]
        AudioQuality[Audio Quality<br/>ğŸµ STT/TTS success rate]
        UserExperience[User Experience<br/>ğŸ‘¤ Interaction patterns]
    end

    ResponseTime --> Logs
    ErrorRate --> Usage
    Throughput --> Costs
    ClientMetrics --> AudioQuality
    AudioQuality --> UserExperience
```

---

## ğŸš€ Deployment Architecture

### **CI/CD Pipeline**

```mermaid
graph LR
    subgraph "Development"
        LocalDev[Local Development<br/>modal serve]
        Testing[Setup Validation<br/>setup_validator.py]
        Security[Security Check<br/>No secrets in code]
    end
    
    subgraph "Deployment"
        Deploy[Production Deploy<br/>modal deploy]
        Monitor[Health Check<br/>Endpoint monitoring]
        Scale[Auto-scaling<br/>Based on demand]
    end
    
    subgraph "Maintenance"
        Updates[Dependency Updates<br/>Regular security patches]
        Backup[Configuration Backup<br/>Modal secrets backup]
        Monitoring[Performance Monitoring<br/>Continuous optimization]
    end

    LocalDev --> Testing
    Testing --> Security
    Security --> Deploy
    Deploy --> Monitor
    Monitor --> Scale
    Scale --> Updates
    Updates --> Backup
    Backup --> Monitoring
```

This architecture demonstrates a **production-grade AI system** with:

- âš¡ **High Performance**: Sub-second AI inference with Groq
- ğŸ”’ **Enterprise Security**: Encrypted secrets, private data handling
- ğŸ“ˆ **Scalable Infrastructure**: Serverless auto-scaling on Modal
- ğŸ›¡ï¸ **Fault Tolerance**: Multiple fallback systems
- ğŸŒ **Modern Tech Stack**: Latest AI APIs and frameworks
- ğŸ“Š **Observability**: Comprehensive monitoring and analytics 